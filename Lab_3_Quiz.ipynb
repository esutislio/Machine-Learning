{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af8fca2",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "## Q1-8: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da2dc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = pd.read_csv(\"advertising.csv\")\n",
    "ss = pd.read_csv(\"superstore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8850b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63bd7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03592ce6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# List all distinct values in ['Category']\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m values_in_category \u001b[38;5;241m=\u001b[39m \u001b[43mss\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m      3\u001b[0m values_in_category\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ss' is not defined"
     ]
    }
   ],
   "source": [
    "# List all distinct values in ['Category']\n",
    "values_in_category = ss['Category'].unique()\n",
    "values_in_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count distinct values in ['Category']\n",
    "count_distinct = ss['Category'].nunique()\n",
    "count_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average sales by category\n",
    "avg_sales = ss.groupby('Category')['Sales'].mean().reset_index()\n",
    "# Rename the \"sales\" column to \"average sales\"\n",
    "avg_sales = avg_sales.rename(columns={'Sales': 'avg_sales'})\n",
    "avg_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Create a barplot of avg sales by category. \n",
    "# Rotate the x-axis by 90. Which category has the highest avg sales?\n",
    "plt.figure(figsize=(8,4)) \n",
    "ax = sns.barplot(x='Category', y='avg_sales', data=avg_sales, estimator=np.max)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 90) # see documentation for other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee00ac1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. Use Seaborn. Create a bar plot showing the count of transactions (rows) in each state. \n",
    "# Rotate the x-axis labels by 90 degrees. \n",
    "# Which state has the most transactions? \n",
    "\n",
    "# Count the transactions group by state\n",
    "trans_state = ss.groupby('State')['Order ID'].count().reset_index()\n",
    "\n",
    "max_order_index = trans_state['Order ID'].idxmax()\n",
    "\n",
    "# Use the index to get the state with the highest number of orders\n",
    "state_with_max_orders = trans_state.loc[max_order_index, 'State']\n",
    "\n",
    "print(\"State with the Highest Number of Orders:\", state_with_max_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6c9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_state = trans_state.rename(columns = {'Order ID':'Count_orders'})\n",
    "trans_state = trans_state.sort_values(by = 'Count_orders' ,ascending=False)\n",
    "trans_state.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f29759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot\n",
    "plt.figure(figsize = (8,6))\n",
    "ax2 = sns.barplot(x='State', y='Count_orders', data=trans_state, estimator = np.max)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot\n",
    "plt.figure(figsize = (8,6))\n",
    "ax2 = sns.barplot(x='State', y='Count_orders', data=trans_state, estimator = np.min)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc35d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Use Seaborn. Create a 'Year' variable extracted from order date. \n",
    "# Something like pd.to_datetime(df['Order Date'], format='%m/%d/%Y').dt.year can work.\n",
    "# Create a bar plot showing average sales in each year based on order date. Rotate the x-axis labels by 90 degrees. \n",
    "# Which year has the highest average sales? \n",
    "\n",
    "ss['Year'] = pd.to_datetime(ss['Order Date'],format='%m/%d/%Y').dt.year\n",
    "\n",
    "avg_sales_year = ss.groupby('Year')['Sales'].mean().reset_index()\n",
    "avg_sales_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d8686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize = (8,4))\n",
    "ax3 = sns.barplot(x = 'Year', y = 'Sales', data = avg_sales_year, estimator = np.max)\n",
    "ax3.set_xticklabels(ax3.get_xticklabels(), rotation = 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f2365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Use Seaborn. Create a figure that includes box plots of distribution of shipping cost for each region. \n",
    "# Which region has the largest range of shipping cost? \n",
    "ss.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b112844",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "ax5 = sns.boxplot(x=\"Region\", y=\"Shipping Cost\", data=ss, palette=\"rainbow\", showfliers = True)\n",
    "ax5\n",
    "# the largest range which includes outliers = Central, exclude outliers = East"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_sorted = ss.sort_values(by = 'Shipping Cost' ,ascending=False)\n",
    "ss.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0efdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_shipcost = ss.groupby('Region')['Shipping Cost'].quantile(0.75).reset_index()\n",
    "med_shipcost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ed933",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Use Seaborn. Create a figure that includes sets of box plots of distribution of shipping cost by ship mode and region. \n",
    "# There should be 4 sets of box plots (1 set for each region). \n",
    "# For each set, there should be 3 box plots (1 for each ship mode).\n",
    "# In total, the figure should include 12 box plots. \n",
    "# Within the central region, which ship mode has the largest range of shipping cost? Delivery Truck\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "ax5 = sns.boxplot(x=\"Region\", y=\"Shipping Cost\", data=ss, palette=\"rainbow\", showfliers = True, hue = \"Ship Mode\")\n",
    "ax5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b05283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 7. Use Seaborn. Create a joint plot with a scatterplot in the middle for shipping cost vs. unit price.\n",
    "# Segment the data points by container. Set xlim=[0, 40] and ylim=[0, 100]. Look at the density plots. \n",
    "# Which type of container is used most often for shipping costs around $20?  \n",
    "\n",
    "sns.jointplot(x='Shipping Cost', y='Unit Price', hue = 'Container', data=ss, kind='scatter') # choose 'reg' for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heat map of pairwise correlations for variables unit price, sales, profit, and shipping cost.\n",
    "columns_corr = ['Unit Price', 'Shipping Cost', 'Profit', 'Sales']\n",
    "corr_matrix = ss[columns_corr].corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162dba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Use Seaborn. Create a heat map of pairwise correlations for variables unit price, sales, profit, and shipping cost.\n",
    "# Which variable has the smallest correlation with unit price?  Profit\n",
    "# Correlations among 3 variables color coded on a heat map\n",
    "# see colors insetad of values\n",
    "sns.heatmap(corr_matrix.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ece5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_corr = ['Unit Price', 'Shipping Cost', 'Profit', 'Sales']\n",
    "corr_matrix = ss[columns_corr]\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.sort_index() # revert back to its original index order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_corr = ['Unit Price', 'Shipping Cost', 'Profit', 'Sales']\n",
    "corr_matrix = ss[columns_corr].sort_index()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc727014",
   "metadata": {},
   "source": [
    "# Logistic Regression Q9-Q16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50829a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages needed \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import * # import all libraries under sklearn.metrics\n",
    "\n",
    "# 2 functions to print out metrics (written by us, not in sklearn)\n",
    "\n",
    "# define a function for calculating the metric to be used later \n",
    "# takes in 2 inputs: Y_pred, Y_true\n",
    "# and uses them to calculate metrics using functions in sklearn\n",
    "def classification_metrics(Y_pred, Y_true):\n",
    "    acc = accuracy_score(Y_true, Y_pred)\n",
    "    precision = precision_score(Y_true, Y_pred)\n",
    "    recall = recall_score(Y_true, Y_pred)\n",
    "    f1score = f1_score(Y_true, Y_pred)\n",
    "    auc = roc_auc_score(Y_true, Y_pred)\n",
    "\n",
    "    # the function's outputs are the 5 variables below\n",
    "    return acc, precision, recall, f1score, auc\n",
    "\n",
    "# define a function for printing the metrics using inputs: classifierName, Y_pred, Y_true\n",
    "# e.g. inputs can be: 'Logistic Regression', y_pred, y_test\n",
    "# inside the function, we do something with the inputs (e.g. run classification_metrics on the inputs)\n",
    "# classification_metrics is antoher function we wrote above\n",
    "def display_metrics(classifierName, Y_pred, Y_true):\n",
    "    print (\"______________________________________________\")\n",
    "    print (\"Model: \"+classifierName)\n",
    "    acc, precision, recall, f1score, auc = classification_metrics(Y_pred, Y_true)\n",
    "    # returns 5 vars: acc, precision, recall, f1score, auc\n",
    "    # print them below\n",
    "    print (\"Accuracy: \"+str(acc))\n",
    "    print (\"Precision: \"+str(precision))\n",
    "    print (\"Recall: \"+str(recall))\n",
    "    print (\"F1-score: \"+str(f1score))\n",
    "    print (\"AUC: \"+str(auc))\n",
    "    print (\"______________________________________________\")\n",
    "    print (\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0dd92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Use sklearn. Train the following logistic regressions with x-variables:\n",
    "\n",
    "\n",
    "# Model 1: Age, Daily Time Spent on Site\n",
    "# Model 2: Age, Daily Time Spent on Site, Area Income, Male\n",
    "# Model 3: Age, Daily Time Spent on Site, Area Income, Male, Daily Internet Usage\n",
    "\n",
    "# Use test_size=0.3, random_state=101 for all models.\n",
    "\n",
    "\n",
    "# Which model has the highest AUC for test data? Enter the model number.\n",
    "\n",
    "# Predicting Logistic Regression using sklearn\n",
    "# 1. Data transformation (creating dummy variables and such)\n",
    "# 2. Define X and Y\n",
    "# 3. Splitting training and test dataset\n",
    "# 4. Define the type of model so like model = LogisticRegression()\n",
    "# 5. Fit the model using the training set model.fit(X_train, y_train)\n",
    "# 6. Predict the y values for the test set using function 'model.predict' so like y_pred= model.predict(X_test)\n",
    "# 7. Create summary y_pred.summary\n",
    "# 8. Calculate the confusion matrix for test data: #display_metrics('LogisticRegression', y_pred, y_test) \n",
    "                    # we have to create the display_metrics function: def display_metrics ....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9503e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2 = ad.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0663b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf179aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2 = pd.concat([ad, pd.get_dummies(ad2['Country'], prefix='Country')], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2.drop(['Country'], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2faa86e",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Age, Daily Time Spent on Site\n",
    "# Model 2: Age, Daily Time Spent on Site, Area Income, Male\n",
    "# Model 3: Age, Daily Time Spent on Site, Area Income, Male, Daily Internet Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors1 = ['Age', 'Daily Time Spent on Site']\n",
    "predictors2 = ['Age', 'Daily Time Spent on Site', 'Area Income', 'Male']\n",
    "predictors3 = ['Age', 'Daily Time Spent on Site', 'Area Income', 'Male', 'Daily Internet Usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1110e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and Y for model 1\n",
    "X = ad2[predictors1]\n",
    "y = ad2['Clicked on Ad']\n",
    "# print('X variables:\\n', [i for i in X.columns]) #Check the columns of the variables\n",
    "\n",
    "# split the dataset into training and test sets (e.g. Use 30% of the data as test data, 70% as training data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Define the type of model using function LogisticRegression()\n",
    "model1 = LogisticRegression()\n",
    "\n",
    "# Fit the model using training set\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Predict the y values for the test set using function 'model.predict'\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "# calculate the confusion matrix for the test data using function 'confusion_matrix' in sklearn\n",
    "# inputs: y_test, y_pred\n",
    "# y_test: true y-values \n",
    "# y_pred: predicted y-values \n",
    "confusion_matrix_results = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# print the counts of the confusion matrix \n",
    "print('confusion matrix: \\n', confusion_matrix_results)\n",
    "\n",
    "# print the metrics using function 'display_metrics' we wrote\n",
    "display_metrics('Logistic Regression', y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45507073",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ad2[predictors2]\n",
    "y = ad2['Clicked on Ad']\n",
    "# print('X variables:\\n', [i for i in X.columns]) #Check the columns of the variables\n",
    "\n",
    "# split the dataset into training and test sets (e.g. Use 30% of the data as test data, 70% as training data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Define the type of model using function LogisticRegression()\n",
    "model2 = LogisticRegression()\n",
    "\n",
    "# Fit the model using training set\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Predict the y values for the test set using function 'model.predict'\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# calculate the confusion matrix for the test data using function 'confusion_matrix' in sklearn\n",
    "# inputs: y_test, y_pred\n",
    "# y_test: true y-values \n",
    "# y_pred: predicted y-values \n",
    "confusion_matrix_results = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# print the counts of the confusion matrix \n",
    "print('confusion matrix: \\n', confusion_matrix_results)\n",
    "\n",
    "# print the metrics using function 'display_metrics' we wrote\n",
    "display_metrics('Logistic Regression', y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c9bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ad2[predictors3]\n",
    "y = ad2['Clicked on Ad']\n",
    "# print('X variables:\\n', [i for i in X.columns]) #Check the columns of the variables\n",
    "\n",
    "# split the dataset into training and test sets (e.g. Use 30% of the data as test data, 70% as training data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Define the type of model using function LogisticRegression()\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "# Fit the model using training set\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Predict the y values for the test set using function 'model.predict'\n",
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "# calculate the confusion matrix for the test data using function 'confusion_matrix' in sklearn\n",
    "# inputs: y_test, y_pred\n",
    "# y_test: true y-values \n",
    "# y_pred: predicted y-values \n",
    "confusion_matrix_results = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# print the counts of the confusion matrix \n",
    "print('confusion matrix: \\n', confusion_matrix_results)\n",
    "\n",
    "# print the metrics using function 'display_metrics' we wrote\n",
    "display_metrics('Logistic Regression', y_pred, y_test)\n",
    "\n",
    "#Answer to Q9: Model 3 has the highest AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab413a",
   "metadata": {},
   "source": [
    "### Question 10: Finding False Negatives (FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Use sklearn. Train the following logistic regression with x-variables: Age, Daily Time Spent on Site, Area Income.\n",
    "# Use test_size=0.3, random_state=101. Create the confusion matrix (1 = positive). \n",
    "\n",
    "# The axes for confusion matrix from sklearn is as below: \n",
    "\n",
    "#                predicted                        \n",
    "#                   0       1     \n",
    "#               -----   -----    \n",
    "#              0|   a   |   c      \n",
    "# actual    -----   -----             \n",
    "#              1|   b   |   d     \n",
    "\n",
    "# How many false negatives are there for the test data? \n",
    "\n",
    "# If you are not getting the correct answers, try using the liblinear solver for logistic regression. \n",
    "# i.e. You can specify this solver be used by sklearn in your code like this: LogisticRegression(solver = 'liblinear'). \n",
    "# If it still does not work and you checked your code, leave your answer as is. I will then grade it manually. \n",
    "\n",
    "predictors4 = ['Age', 'Daily Time Spent on Site', 'Area Income', 'Male']\n",
    "X = ad2[predictors4]\n",
    "y = ad2['Clicked on Ad']\n",
    "\n",
    "# split the dataset into training and test sets (e.g. Use 30% of the data as test data, 70% as training data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Define the type of model using function LogisticRegression()\n",
    "model4 = LogisticRegression(solver='liblinear', random_state=101)\n",
    "\n",
    "# Fit the model using training set\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "# Predict the y values for the test set using function 'model.predict'\n",
    "y_pred = model4.predict(X_test)\n",
    "\n",
    "# calculate the confusion matrix for the test data using function 'confusion_matrix' in sklearn\n",
    "confusion_matrix_results4 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# print the counts of the confusion matrix \n",
    "print('confusion matrix: \\n', confusion_matrix_results4)\n",
    "\n",
    "# print the metrics using function 'display_metrics' we wrote\n",
    "display_metrics('Logistic Regression', y_pred, y_test)\n",
    "'''\n",
    "# Extract the number of false negatives (FN)\n",
    "count_FN = confusion_matrix_results4[1][0]\n",
    "\n",
    "print(\"Number of False Negatives:\", false_negatives)\n",
    "'''\n",
    "\n",
    "'''\n",
    "confusion is a 2x2 matrix where:\n",
    "confusion[0][0] represents the count of true negatives (TN).\n",
    "confusion[0][1] represents the count of false positives (FP).\n",
    "confusion[1][0] represents the count of false negatives (FN).\n",
    "confusion[1][1] represents the count of true positives (TP).\n",
    "'''\n",
    "'''\n",
    "             Predicted\n",
    "               0       1\n",
    "Actual    -----   -----\n",
    "       0 |   TN   |   FP\n",
    "       1 |   FN   |   TP\n",
    "\n",
    "FN = Actual Positive (1) and Predicted Negative (0) --> [1][0]\n",
    "TP = Actual True and Predicted True [1,1]\n",
    "FP = Actual Negative (0), predicted positive (1) [0,1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6fdb28",
   "metadata": {},
   "source": [
    "### Question 11: Finding False Positives (FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Use sklearn. Train the following logistic regression with\n",
    "#  x-variables: Age, Daily Time Spent on Site, Area Income, Male, Daily Internet Usage\n",
    "# Use test_size=0.3, random_state=101. Create the confusion matrix (1 = positive). \n",
    "\n",
    "# How many false positives are there for the test data? \n",
    "\n",
    "predictors11 = ['Age', 'Daily Time Spent on Site', 'Area Income', 'Male', 'Daily Internet Usage']\n",
    "X = ad2[predictors11]\n",
    "y = ad2['Clicked on Ad']\n",
    "\n",
    "# split the dataset into training and test sets (e.g. Use 30% of the data as test data, 70% as training data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Define the type of model using function LogisticRegression()\n",
    "model11 = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Fit the model using training set\n",
    "model11.fit(X_train, y_train)\n",
    "\n",
    "# Predict the y values for the test set using function 'model.predict'\n",
    "y_pred = model11.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusionmax11 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract the number of FP\n",
    "FP_11 = confusionmax11[0][1]\n",
    "print(\"Number of False Negatives:\", false_negatives)\n",
    "\n",
    "'''\n",
    "# calculate the confusion matrix for the test data using function 'confusion_matrix' in sklearn\n",
    "confusion_matrix_results11 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# print the counts of the confusion matrix \n",
    "print('confusion matrix: \\n', confusion_matrix_results11)\n",
    "\n",
    "# print the metrics using function 'display_metrics' we wrote\n",
    "display_metrics('Logistic Regression', y_pred, y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d46485",
   "metadata": {},
   "source": [
    "### Question 12: Create a loop to find the best accuracy rate from different test sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da294dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Use sklearn. Train 5 logistic regressions with \n",
    "# x-variables: Age, Daily Time Spent on Site, Area Income, Male, Daily Internet Usage\n",
    "# Vary the test size for each model (use 30%, 40%, 50%, 60%, 70%). Use random_state=101.\n",
    "\n",
    "# What is the average accuracy for the 5 models for the test set? Round to 2 decimals.\n",
    "\n",
    "# You may use the code below and fill in the 2 TODO sections (to set up X and y; and to calculate y_pred)\n",
    "\n",
    "\n",
    "predictors_12 = ['Age', 'Daily Time Spent on Site', 'Area Income', 'Male', 'Daily Internet Usage']\n",
    "ad2_X = ad2[predictors_12]\n",
    "ad2_y = ad2['Clicked on Ad']\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "test_sizes = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "for i in test_sizes: \n",
    "    X_train, X_test, y_train, y_test = train_test_split(ad2_X,ad2_y, test_size=i, random_state=101)\n",
    "    model12 = LogisticRegression(solver = 'liblinear')\n",
    "    model12.fit(X_train, y_train)\n",
    "    y_pred = model12.predict(X_test)\n",
    "    acc, precision, recall, f1score, auc = classification_metrics(y_pred, y_test)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "np.mean(accuracies)\n",
    "print(accuracies)\n",
    "print(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2:\n",
    "\n",
    "mod3x = advertising[['Age', 'Daily Time Spent on Site', 'Area Income', 'Male', 'Daily Internet Usage']]\n",
    "\n",
    "#Preparation\n",
    "accuracies = []\n",
    "testSizes = np.arange(0.3, 0.8, 0.1)\n",
    "testSizes\n",
    "\n",
    "#For loop\n",
    "for i in testSizes:\n",
    "    xQ12tr, xQ12te, yQ12tr, yQ12te = train_test_split(mod3x, y, test_size = i, random_state = 101)\n",
    "    modQ12 = LogisticRegression()\n",
    "    modQ12.fit(xQ12tr, yQ12tr)\n",
    "    yQ12Pred = modQ12.predict(xQ12te)\n",
    "\n",
    "    acc, precision, recall, f1score, auc = classification_metrics(yQ12Pred, yQ12te)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "\n",
    "np.mean(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2 = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.read_csv('Superstore.csv')\n",
    "advertise = pd.read_csv('advertising.csv')\n",
    "\n",
    "advertise_x = advertise[['Age', 'Daily Time Spent on Site', 'Area Income', 'Male', 'Daily Internet Usage']]\n",
    "advertise_y = advertise[['Clicked on Ad']]\n",
    "\n",
    "accuracies = []\n",
    "test_sizes = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "for i in test_sizes:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(advertise_x, advertise_y, test_size = i, random_state=101)\n",
    "    \n",
    "    clf = LogisticRegression(random_state = 101, solver ='liblinear').fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc, precision, recall, f1score, auc = classification_metrics(y_pred, y_test)\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    \n",
    "np.mean(accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150fac5",
   "metadata": {},
   "source": [
    "### Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb5d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_sizes, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(test_sizes, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('Accuracy vs. Test Size')\n",
    "plt.xlabel('Test Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "# Find the test size with the highest accuracy\n",
    "best_test_size = test_sizes[np.argmax(accuracies)]\n",
    "\n",
    "# Round the best test size to 2 decimal places\n",
    "best_test_size = round(best_test_size, 2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"The test size that generated the highest accuracy is {best_test_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cfc35c",
   "metadata": {},
   "source": [
    "### Question 14: StatsModel (Using dummy variables as predictor variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5418b29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m predictors14 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaily Time Spent on Site\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArea Income\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaily Internet Usage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ad2\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m)][\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m      7\u001b[0m X \u001b[38;5;241m=\u001b[39m ad2[predictors14] \n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mLogit(\u001b[43my\u001b[49m, X)\u001b[38;5;241m.\u001b[39mfit() \n\u001b[0;32m      9\u001b[0m result\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# ad.head()\n",
    "ad2 = ad.copy()\n",
    "ad2 = pd.concat([ad2, pd.get_dummies(ad2['Country'], prefix='Country')], axis = 1)\n",
    "ad2.drop(['Country'], axis = 1, inplace= True)\n",
    "predictors14 = ['Age', 'Daily Time Spent on Site', 'Area Income', 'Male', 'Daily Internet Usage']+[i for i in ad2.columns if i.startswith('Country')][1:]\n",
    "\n",
    "X = ad2[predictors14] \n",
    "model = sm.Logit(y, X).fit() \n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f9a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Question 14\n",
    "advertise = pd.read_csv('advertising.csv')\n",
    "advertise_x = advertise[['Age', 'Daily Time Spent on Site', 'Area Income', 'Male', 'Daily Internet Usage']]\n",
    "advertise_y = advertise[['Clicked on Ad']]\n",
    "\n",
    "country_dummy = pd.get_dummies(advertise['Country'])\n",
    "advertise_x_with_dummy = pd.concat([advertise_x, country_dummy], axis = 1)\n",
    "\n",
    "log_reg = sm.Logit(advertise_y, advertise_x_with_dummy).fit()\n",
    "print(log_reg.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d9a57",
   "metadata": {},
   "source": [
    "### Question 15: Extract variables like MONTH() & Dummy variables with Statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2['Month'] = pd.to_datetime(ad2['Timestamp'], format='%Y-%m-%d %H:%M').dt.month\n",
    "ad2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61b278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 15. Use statsmodels, run a logistic regression with \n",
    "# x-variables: Age, Daily Time Spent on Site, Area Income, Male, Daily Internet Usage, Month, and Country dummies\n",
    "# Create a new variable 'Month' by extracting month from timestamp. \n",
    "# Something like ad_data['Month'] = pd.to_datetime(ad_data['Timestamp'], format='%Y-%m-%d %H:%M').dt.month can work. 0.21\n",
    "\n",
    "# What is the coefficient for month? Round to nearest 2 decimals. \n",
    "predictors_15=['Age', 'Daily Time Spent on Site', 'Area Income', 'Male', 'Daily Internet Usage', 'Month']+[i for i in ad2.columns if i.startswith('Country')][1:]\n",
    "X = ad2[predictors_15]\n",
    "model_15 = sm.Logit(y, X)\n",
    "result_15 = model_15.fit() \n",
    "result_15.summary2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a4e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238269b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7470c06a",
   "metadata": {},
   "source": [
    "### Question 16: Extract variables like MONTH() & HOUR(), Dummy variables with Statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21958748",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ad2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 16. Use statsmodels, run a logistic regression with \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# x-variables: Age, Daily Time Spent on Site, Area Income, Male, Daily Internet Usage, Month, Hour, and Country dummies\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create a new variable 'Hour' by extracting hour from timestamp. Use pd.to_datetime() as above,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# but change a parameter to extract hour. 0.06\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# What is the coefficient for hour? Round to nearest 2 decimals. \u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m ad2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mad2\u001b[49m\u001b[38;5;241m.\u001b[39mTimestamp, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[0;32m      9\u001b[0m ad2\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ad2' is not defined"
     ]
    }
   ],
   "source": [
    "# 16. Use statsmodels, run a logistic regression with \n",
    "# x-variables: Age, Daily Time Spent on Site, Area Income, Male, Daily Internet Usage, Month, Hour, and Country dummies\n",
    "# Create a new variable 'Hour' by extracting hour from timestamp. Use pd.to_datetime() as above,\n",
    "# but change a parameter to extract hour. 0.06\n",
    "\n",
    "# What is the coefficient for hour? Round to nearest 2 decimals. \n",
    "\n",
    "ad2['Hour'] = pd.to_datetime(ad2.Timestamp, format='%Y-%m-%d %H:%M').dt.hour\n",
    "ad2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00f33f76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ad2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictors_16\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaily Time Spent on Site\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArea Income\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaily Internet Usage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mad2\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m)][\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m ad2[predictors_16]\n\u001b[0;32m      4\u001b[0m model22 \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mLogit(y, X)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ad2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "predictors_16=['Age', 'Daily Time Spent on Site', 'Area Income', 'Male', 'Daily Internet Usage', 'Month', 'Hour']+[i for i in ad2.columns if i.startswith('Country')][1:]\n",
    "X = ad2[predictors_16]\n",
    "\n",
    "model22 = sm.Logit(y, X)\n",
    "result22 = model22.fit() \n",
    "result22.summary2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f064f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(ad2[predictors_16])\n",
    "model_16 = sm.Logit(y, X)\n",
    "result_16 = model_16.fit() \n",
    "result_16.summary()\n",
    "# Extract the coefficients from the result summary\n",
    "coefficients = result_16.params\n",
    "\n",
    "# Extract the coefficient for 'Hour'\n",
    "hour_coefficient = coefficients['Hour']\n",
    "\n",
    "# Extract the coefficient for 'Month'\n",
    "month_coefficient = coefficients['Month']\n",
    "\n",
    "# Round the coefficients to the nearest two decimals\n",
    "rounded_hour_coefficient = round(hour_coefficient, 2)\n",
    "rounded_month_coefficient = round(month_coefficient, 2)\n",
    "\n",
    "# Print the coefficients\n",
    "print(f\"The coefficient for 'Hour' is: {rounded_hour_coefficient}\")\n",
    "print(f\"The coefficient for 'Month' is: {rounded_month_coefficient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14376ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthEx = pd.to_datetime(ad2.Timestamp, format = '%Y-%m-%d %H:%M').dt.month\n",
    "monthEx\n",
    "xQ15 = Q14dat.drop(['Ad Topic Line', 'Timestamp', 'Clicked on Ad'], axis = 1)\n",
    "xQ15.info()\n",
    "modQ15 = sm.Logit(y, xQ15)\n",
    "result = modQ15.fit()\n",
    "result.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36fbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the independent variables (x-variables)\n",
    "x_variables = ['Age', 'Daily Time Spent on Site', 'Area Income', 'Male', 'Daily Internet Usage', 'Month'] + [col for col in ad2.columns if col.startswith('Country_')]\n",
    "\n",
    "# Add a constant term (intercept)\n",
    "X = sm.add_constant(ad2[x_variables])\n",
    "\n",
    "# Define the dependent variable (target variable)\n",
    "y = ad2['Clicked on Ad']\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Get the summary of the logistic regression model\n",
    "summary = result.summary()\n",
    "\n",
    "# Extract the coefficient for the 'Month' variable\n",
    "month_coefficient = result.params['Month']\n",
    "\n",
    "# Round the coefficient to 2 decimals\n",
    "rounded_month_coefficient = round(month_coefficient, 2)\n",
    "\n",
    "# Print the summary and the rounded coefficient for 'Month'\n",
    "print(summary2)\n",
    "print(f\"Coefficient for 'Month': {rounded_month_coefficient}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = ad.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0359cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffdf299",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad3=ad2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20970992",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad4 = ad3.drop(['Ad Topic Line', 'Timestamp', 'Clicked on Ad', 'Country_Afghanistan'], axis = 1)\n",
    "\n",
    "modelQ15 = sm.Logit(y, ad4)\n",
    "result_15v2 = modelQ15.fit()\n",
    "result_15v2.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff93a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ad5 = ad3.drop(['Ad Topic Line', 'Timestamp', 'Clicked on Ad', 'Hour', 'Country_Afghanistan'], axis = 1)\n",
    "\n",
    "modelQ16 = sm.Logit(y, ad5)\n",
    "result_16v2 = modelQ16.fit()\n",
    "result_16v2.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a32ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
